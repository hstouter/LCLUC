{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download packages\n",
    "import json\n",
    "import requests\n",
    "from getpass import getpass\n",
    "import sys\n",
    "import time\n",
    "import re\n",
    "import threading\n",
    "import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import pyproj\n",
    "from shapely.geometry import box\n",
    "from shapely import wkt\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to M2M server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send HTTP request to connect to server \n",
    "def sendRequest(url, data, apiKey=None, exitIfNoResponse=True):\n",
    "    \"\"\"\n",
    "    Send a request to an M2M (Machine-to-Machine) endpoint and return the parsed JSON response.\n",
    "\n",
    "    Parameters:\n",
    "    - url (str): The URL of the M2M endpoint.\n",
    "    - data (dict): The payload to be sent with the request.\n",
    "    - apiKey (str, optional): An optional API key for authorization. If not provided, the request will be sent without an authorization header.\n",
    "    - exitIfNoResponse (bool, optional): If True, the program will exit upon receiving an error or no response. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "    - dict: The parsed JSON response containing the data, or False if there was an error.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert payload to json string\n",
    "    json_data = json.dumps(data)\n",
    "    \n",
    "    if apiKey == None:\n",
    "        response = requests.post(url, json_data)\n",
    "    else:\n",
    "        headers = {'X-Auth-Token': apiKey}              \n",
    "        response = requests.post(url, json_data, headers = headers)  \n",
    "    \n",
    "    try:\n",
    "      httpStatusCode = response.status_code \n",
    "      if response == None:\n",
    "          print(\"No output from service\")\n",
    "          if exitIfNoResponse: sys.exit()\n",
    "          else: return False\n",
    "      output = json.loads(response.text)\n",
    "      if output['errorCode'] != None:\n",
    "          print(output['errorCode'], \"- \", output['errorMessage'])\n",
    "          if exitIfNoResponse: sys.exit()\n",
    "          else: return False\n",
    "      if  httpStatusCode == 404:\n",
    "          print(\"404 Not Found\")\n",
    "          if exitIfNoResponse: sys.exit()\n",
    "          else: return False\n",
    "      elif httpStatusCode == 401: \n",
    "          print(\"401 Unauthorized\")\n",
    "          if exitIfNoResponse: sys.exit()\n",
    "          else: return False\n",
    "      elif httpStatusCode == 400:\n",
    "          print(\"Error Code\", httpStatusCode)\n",
    "          if exitIfNoResponse: sys.exit()\n",
    "          else: return False\n",
    "    except Exception as e: \n",
    "          response.close()\n",
    "          print(e)\n",
    "          if exitIfNoResponse: sys.exit()\n",
    "          else: return False\n",
    "    response.close()\n",
    "    \n",
    "    return output['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serviceUrl = \"https://m2m.cr.usgs.gov/api/api/json/stable/\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadFile(url, out_dir):\n",
    "    sema.acquire()\n",
    "    try:\n",
    "        response = requests.get(url, stream=True)\n",
    "        disposition = response.headers['content-disposition']\n",
    "        filename = re.findall(\"filename=(.+)\", disposition)[0].strip(\"\\\"\")\n",
    "        print(f\"    Downloading: {filename} -- {url}...\")\n",
    "        \n",
    "        open(os.path.join(out_dir, filename), 'wb').write(response.content)\n",
    "        sema.release()\n",
    "    except Exception as e:\n",
    "        print(f\"\\nFailed to download from {url}. Will try to re-download.\")\n",
    "        sema.release()\n",
    "        runDownload(threads, url, out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxthreads = 5 # Threads count for downloads\n",
    "sema = threading.Semaphore(value=maxthreads)\n",
    "label = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") # Customized label using date time\n",
    "threads = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runDownload(threads, url, out_dir):\n",
    "    thread = threading.Thread(target=downloadFile, args=(url,out_dir,))\n",
    "    threads.append(thread)\n",
    "    thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set output directory\n",
    "outDir= '/Users/hstouter/Library/CloudStorage/Box-Box/LCLUC_hs/Landsat_USGS/2024'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to USGS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = \"hstouter\"\n",
    "token = \"H3xVeg!r!zyZoWtWqt2@uvIKIJVZ_ntvs89MIMLFMj6HRZWhewdPTor9C5iXQ@Ez\"\n",
    "\n",
    "\n",
    "login_payload = {'username' : username, 'token' : token}\n",
    "apiKey = sendRequest(serviceUrl + \"login-token\", login_payload)\n",
    "print(\"API Key: \" + apiKey + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define ROI from .shp file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   OBJECTID_1  OBJECTID       boundary heritage_o         leisure  \\\n",
      "0           1         1  national_park        whc  nature_reserve   \n",
      "\n",
      "                      name               name_de             name_en  \\\n",
      "0  Réserve de faune du Dja  Wildtierreservat Dja  Dja Faunal Reserve   \n",
      "\n",
      "                   name_es                  name_fr  ... source waterway  \\\n",
      "0  Reserva de fauna de Dja  Réserve de faune du Dja  ...   None     None   \n",
      "\n",
      "  fixme place BUFF_DIST ORIG_FID Shape_Leng Shape_Le_1 Shape_Area  \\\n",
      "0  None  None     300.0        0    19.8677  25.093084  39.287694   \n",
      "\n",
      "                                            geometry  \n",
      "0  POLYGON ((9.7339 0.12708, 9.7339 6.14299, 16.2...  \n",
      "\n",
      "[1 rows x 31 columns]\n",
      "original : EPSG:4326\n",
      "updated : EPSG:4326\n",
      "{'filterType': 'geojson', 'geoJson': {'type': 'Polygon', 'coordinates': (((16.264536521943, 0.12707961553189762), (9.733902788682826, 0.12707961553189762), (9.733902788682826, 6.142988004392919), (16.264536521943, 6.142988004392919), (16.264536521943, 0.12707961553189762)),)}}\n"
     ]
    }
   ],
   "source": [
    "# to get correct CRS\n",
    "# pyproj.datadir.set_data_dir(\"/Users/hstouter/anaconda3/envs/remote_sensing/share/proj\")\n",
    "\n",
    "# Study area shp\n",
    "shp_path = (\"/Users/hstouter/Desktop/NASA_LCLUC/LCLUC Mapping/Dja_300km_buffer_envelope/Dja_300km_buffer_envelope.shp\")\n",
    "shp = gpd.read_file(shp_path)\n",
    "print(shp.head())\n",
    "\n",
    "# Check CRS & update if needed\n",
    "print(\"original :\", shp.crs)\n",
    "\n",
    "# Update CRS\n",
    "shp = shp.to_crs(epsg=4326)\n",
    "print(\"updated :\", shp.crs)\n",
    "\n",
    "# Get bounding box coordinates\n",
    "minx, miny, maxx, maxy = shp.total_bounds\n",
    "\n",
    "# Create a shapely box (polygon)\n",
    "bbox = box(minx, miny, maxx, maxy)\n",
    "\n",
    "# Fix geometry (ensure it's valid and CCW)\n",
    "bbox_fixed = bbox.buffer(0)\n",
    "\n",
    "\n",
    "# Convert to GeoJSON-like dict\n",
    "roi = bbox_fixed.__geo_interface__\n",
    "\n",
    "# Wrap in API spatialFilter format\n",
    "roi = {\n",
    "    'filterType': 'geojson',\n",
    "    'geoJson': roi\n",
    "}\n",
    "\n",
    "print(roi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define JSON inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetName = 'landsat_ot_c2_l2'\n",
    "spatialFiler = roi\n",
    "aquisitionFilter = {'start' : '2024-10-01', 'end' : '2025-09-30'}\n",
    "cloudCoverFilter = {'min' : 0, 'max' : 80}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_payload = {\n",
    "    'datasetName' : datasetName,\n",
    "    'sceneFilter' : {\n",
    "        'spatialFilter' : spatialFiler,\n",
    "        'acquisitionFilter' : aquisitionFilter,\n",
    "        'cloudCoverFilter' : cloudCoverFilter\n",
    "    }\n",
    "}\n",
    "\n",
    "search_payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scenes = sendRequest(serviceUrl + \"scene-search\", search_payload, apiKey) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.json_normalize(scenes['results']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scene ID list\n",
    "{'listId': 'temp_landsat_ot_c2_l2_list',\n",
    "     'idField': 'entityId',\n",
    "     'entityIds': ['LC08_L2SP_068017_20200310_20200822_02_T1', 'LC08_L2SP_068018_20200310_20200822_02_T1'],\n",
    "     'datasetName': 'landsat_ot_c2_l2'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idField = 'entityId'\n",
    "\n",
    "# entityIds = []\n",
    "\n",
    "# for result in scenes['results']:\n",
    "#      # Add this scene to the list I would like to download if bulk is available\n",
    "#     if result['options']['bulk'] == True:\n",
    "#         entityIds.append(result[idField])\n",
    "    \n",
    "# entityIds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull in csv with all landsat scenes and convert to scene list\n",
    "df = pd.read_csv(\n",
    "    \"/Users/hstouter/Library/CloudStorage/Box-Box/LCLUC_hs/Landsat_USGS/scene_ids/2024_landsat_ot_c2_l2_695f3449892201d9.csv\",\n",
    "    encoding=\"latin1\"\n",
    ")\n",
    "\n",
    "print(\"Number of rows df:\", len(df))\n",
    "\n",
    "# Pull column \n",
    "ls_scenes = df[\"Landsat Scene Identifier\"]\n",
    "print(ls_scenes.head())\n",
    "\n",
    "# Convert same format as searching through lists\n",
    "ls_scenes = (\n",
    "    df[\"Landsat Scene Identifier\"]\n",
    "    .astype(str)\n",
    "    .str.strip()\n",
    "    .tolist()\n",
    ")\n",
    "\n",
    "ls_scenes\n",
    "\n",
    "ls_scenes = ls_scenes[1:5] # test with first 5 scenes\n",
    "print(\"Number of scenes:\", len(ls_scenes))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idField = 'entityId'\n",
    "listId = f\"temp_{datasetName}_list\"\n",
    "\n",
    "scn_list_add_payload = {\n",
    "    \"listId\": listId,\n",
    "    'idField' : idField,\n",
    "    \"entityIds\": ls_scenes,\n",
    "    \"datasetName\": \"landsat_ot_c2_l2\"\n",
    "}\n",
    "\n",
    "print(\"Number of scenes:\", len(ls_scenes))\n",
    "scn_list_add_payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = sendRequest(serviceUrl + \"scene-list-add\", scn_list_add_payload, apiKey) \n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sendRequest(serviceUrl + \"scene-list-get\", {'listId' : scn_list_add_payload['listId']}, apiKey)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to support download "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_download_options(listId, datasetName, bandGroup):\n",
    "    \"\"\"\n",
    "    Retrieve download options for a specified dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - listId (str): The identifier for the list of items to download.\n",
    "    - datasetName (str): The name of the dataset from which to obtain download options.\n",
    "    - bandGroup (bool): A flag indicating whether to include secondary file groups. \n",
    "                        If True, secondary file groups will be included in the payload.\n",
    "\n",
    "    Returns:\n",
    "    - dict: A dictionary containing the available products for download.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Prepare the payload for the download options request\n",
    "    download_opt_payload = {\n",
    "        \"listId\": listId,              \n",
    "        \"datasetName\": datasetName      \n",
    "    }\n",
    "\n",
    "    # If bandGroup is specified, include the secondary file groups in the payload\n",
    "    if bandGroup:\n",
    "        download_opt_payload['includeSecondaryFileGroups'] = True\n",
    "\n",
    "    # Print the payload for debugging purposes\n",
    "    print(f\"download_opt_payload: {download_opt_payload}\")\n",
    "    \n",
    "    # Send request to the download options endpoint and retrieve list of available products\n",
    "    products = sendRequest(serviceUrl + \"download-options\", download_opt_payload, apiKey)\n",
    "    \n",
    "    return products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_download_request(download_req_payload):\n",
    "    \"\"\"\n",
    "    Sends a download request to the specified service and handles the response.\n",
    "\n",
    "    Parameters:\n",
    "    - download_req_payload (dict): The payload containing parameters needed to execute the download request. example: \n",
    "                                    {\n",
    "                                    \"downloads\": [{'entityId': 'L2SR_LC08_L2SP_068018_20200310_20200822_02_T1_SR_B2_TIF',\n",
    "                                                       'productId': '5f85f041a2ea6695'},\n",
    "                                                      {'entityId': 'L2ST_LC08_L2SP_068018_20200310_20200822_02_T1_ST_B10_TIF',\n",
    "                                                       'productId': '5f85f041a2ea6695'}],\n",
    "                                    \"label\": '20250108_174449'\n",
    "                                    } \n",
    "                                    where downloads is a list of entityIds and productIds for each Item being downloaded and a \"label\" is \n",
    "                                    a user define string \n",
    "    \n",
    "    Returns:\n",
    "    - dict: A dictionary of available URLs\n",
    "    \n",
    "    Exits the program if no records are returned from the download request.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"Sending a download request...\")\n",
    "    \n",
    "    # Send the download request using the provided payload and store the results\n",
    "    download_request_results = sendRequest(serviceUrl + \"download-request\", download_req_payload, apiKey)\n",
    "\n",
    "    # Check if any new records or duplicate products were returned\n",
    "    if len(download_request_results['newRecords']) == 0 and len(download_request_results['duplicateProducts']) == 0:\n",
    "        print('No records returned, please update your scenes or scene-search filter')\n",
    "        sys.exit()\n",
    "    else:\n",
    "        return download_request_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_download_retrieve(download_request_results, outDir):\n",
    "    threads = []\n",
    "    \n",
    "    # Attempt to download URLs if available\n",
    "    if len(download_request_results['availableDownloads']) > 0:\n",
    "        print(f\"Downloading {len(download_request_results['availableDownloads'])} files... Please do not close the program\\n\")\n",
    "        for result in download_request_results['availableDownloads']:  \n",
    "            # print(f\"Get download url: {result['url']}\\n\" )\n",
    "            runDownload(threads, result, outDir)\n",
    "    \n",
    "    # Get items labeled as being prepared for Download\n",
    "    elif len(download_request_results['preparingDownloads']) > 0:\n",
    "        print(f\"Preparing Downloads for {len(download_request_results['preparingDownloads'])} files... Please do not close the program\\n\")\n",
    "    \n",
    "        preparingDownloadIds = []\n",
    "    \n",
    "        for result in download_request_results['preparingDownloads']:  \n",
    "            preparingDownloadIds.append(result['downloadId'])\n",
    "    \n",
    "        download_ret_payload = {\"label\" : download_req_payload['label']}                \n",
    "        # Retrieve download URLs\n",
    "        print(\"Retrieving download urls...\\n\")\n",
    "        download_retrieve_results = sendRequest(serviceUrl + \"download-retrieve\", download_ret_payload, apiKey, False)\n",
    "        print(f\"download_retrieve_results: {download_retrieve_results}\")\n",
    "        if download_retrieve_results != False:\n",
    "            print(f\"    Download-retrieve complete: \\n\" )\n",
    "            for result in download_retrieve_results['available']:\n",
    "                if result['downloadId'] in preparingDownloadIds:\n",
    "                    preparingDownloadIds.remove(result['downloadId'])\n",
    "                    runDownload(threads, result, outDir)\n",
    "                    print(f\"       {result['url']}\\n\" )\n",
    "    \n",
    "            for result in download_retrieve_results['requested']:   \n",
    "                if result['downloadId'] in preparingDownloadIds:\n",
    "                    preparingDownloadIds.remove(result['downloadId'])\n",
    "                    runDownload(threads, result, outDir)\n",
    "                    print(f\"       {result['url']}\\n\" )\n",
    "    \n",
    "        # Didn't get all download URLs, retrieve again after 30 seconds\n",
    "        while len(preparingDownloadIds) > 0: \n",
    "            print(f\"{len(preparingDownloadIds)} downloads are not available yet. Waiting for 30s to retrieve again\\n\")\n",
    "            time.sleep(30)\n",
    "            download_retrieve_results = sendRequest(serviceUrl + \"download-retrieve\", download_ret_payload, apiKey, False)\n",
    "            if download_retrieve_results != False:\n",
    "                for result in download_retrieve_results['available']:                            \n",
    "                    if result['downloadId'] in preparingDownloadIds:\n",
    "                        preparingDownloadIds.remove(result['downloadId'])\n",
    "                        print(f\"    Get download url: {result['url']}\\n\" )\n",
    "                        runDownload(threads, result, outDir)\n",
    "    \n",
    "    for thread in threads:\n",
    "        thread.join()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandNames = {'SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6','SR_B7', 'ST_B10','QA_PIXEL'} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create download request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your output directory\n",
    "outDir = (\"/Users/hstouter/Library/CloudStorage/Box-Box/LCLUC_hs/Landsat_USGS/2024\")\n",
    "os.chdir(outDir)  # switch to that directory\n",
    "print(outDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = get_download_options(listId, datasetName, False) \n",
    "\n",
    "print(products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.json_normalize(products) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloads = []\n",
    "for product in products:  \n",
    "    if product[\"secondaryDownloads\"] is not None and len(product[\"secondaryDownloads\"]) > 0:\n",
    "        for secondaryDownload in product[\"secondaryDownloads\"]:\n",
    "            for bandName in bandNames:\n",
    "                if secondaryDownload[\"bulkAvailable\"] and bandName in secondaryDownload['displayId']:\n",
    "                    downloads.append({\"entityId\":secondaryDownload[\"entityId\"], \"productId\":secondaryDownload[\"id\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_req_payload = {\n",
    "        \"downloads\": downloads,\n",
    "        \"label\": label\n",
    "    }\n",
    "\n",
    "download_req_payload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send download request "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_request_results = run_download_request(download_req_payload) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sending the request and downloading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send HTTP request\n",
    "def sendRequest(url, data, apiKey=None, exitIfNoResponse=True):\n",
    "    \"\"\"\n",
    "    Send a request to an M2M (Machine-to-Machine) endpoint and return the parsed JSON response.\n",
    "\n",
    "    Parameters:\n",
    "    - url (str): The URL of the M2M endpoint.\n",
    "    - data (dict): The payload to be sent with the request.\n",
    "    - apiKey (str, optional): An optional API key for authorization. If not provided, the request will be sent without an authorization header.\n",
    "    - exitIfNoResponse (bool, optional): If True, the program will exit upon receiving an error or no response. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "    - dict: The parsed JSON response containing the data, or False if there was an error.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert payload to json string\n",
    "    json_data = json.dumps(data)\n",
    "    \n",
    "    if apiKey == None:\n",
    "        response = requests.post(url, json_data)\n",
    "    else:\n",
    "        headers = {'X-Auth-Token': apiKey}              \n",
    "        response = requests.post(url, json_data, headers = headers)  \n",
    "    \n",
    "    try:\n",
    "      httpStatusCode = response.status_code \n",
    "      if response == None:\n",
    "          print(\"No output from service\")\n",
    "          if exitIfNoResponse: sys.exit()\n",
    "          else: return False\n",
    "      output = json.loads(response.text)\n",
    "      if output['errorCode'] != None:\n",
    "          print(output['errorCode'], \"- \", output['errorMessage'])\n",
    "          if exitIfNoResponse: sys.exit()\n",
    "          else: return False\n",
    "      if  httpStatusCode == 404:\n",
    "          print(\"404 Not Found\")\n",
    "          if exitIfNoResponse: sys.exit()\n",
    "          else: return False\n",
    "      elif httpStatusCode == 401: \n",
    "          print(\"401 Unauthorized\")\n",
    "          if exitIfNoResponse: sys.exit()\n",
    "          else: return False\n",
    "      elif httpStatusCode == 400:\n",
    "          print(\"Error Code\", httpStatusCode)\n",
    "          if exitIfNoResponse: sys.exit()\n",
    "          else: return False\n",
    "    except Exception as e: \n",
    "          response.close()\n",
    "          print(e)\n",
    "          if exitIfNoResponse: sys.exit()\n",
    "          else: return False\n",
    "    response.close()\n",
    "    \n",
    "    return output['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serviceUrl = \"https://m2m.cr.usgs.gov/api/api/json/stable/\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sha(filepath, checksum_type):\n",
    "    try:\n",
    "        if checksum_type == 'sha512':\n",
    "            sha512 = hashlib.sha512()\n",
    "            BUF_SIZE = 65536\n",
    "\n",
    "            with open(filepath, 'rb') as f:\n",
    "                while True:\n",
    "                    data = f.read(BUF_SIZE)\n",
    "                    if not data:\n",
    "                        break\n",
    "                    sha512.update(data)\n",
    "                    \n",
    "            local_sha = sha512.hexdigest()\n",
    "            return local_sha\n",
    "\n",
    "    except:\n",
    "        print(f'Error Generating Checksum for file: {filepath}')\n",
    "\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadFile(download_rq_result, out_dir):\n",
    "    sema.acquire()\n",
    "    url = download_rq_result['url']\n",
    "    try:\n",
    "        response = requests.get(url, stream=True)\n",
    "        disposition = response.headers['content-disposition']\n",
    "        filename = re.findall(\"filename=(.+)\", disposition)[0].strip(\"\\\"\")\n",
    "        print(f\"> Downloading: {filename} -- {url}...\")\n",
    "\n",
    "        # Save file in out directory\n",
    "        open(os.path.join(out_dir, filename), 'wb').write(response.content)\n",
    "\n",
    "        # Landsat Products currently have SHA-512 checksums\n",
    "        checksum_type = download_rq_result['checksum_values'][0]['id']\n",
    "        print(checksum_type)\n",
    "        if 'checksum_values' in download_rq_result:\n",
    "            \n",
    "            # Generate the checksum from the downloaded file\n",
    "            generated_checksum = generate_sha(os.path.join(out_dir, filename), checksum_type)\n",
    "            checksum_values = []\n",
    "            checksum_values.append([checksum_val['value'] for checksum_val in download_rq_result['checksum_values']])\n",
    "            \n",
    "            if (any( generated_checksum in c for c in checksum_values)):\n",
    "                print(f\"    Checksum validation PASSED for {filename}.\")\n",
    "                print(f\"    {checksum_type}: {generated_checksum}\")\n",
    "            else:\n",
    "                print(f\"    !Checksum validation FAILED for {filename}\")\n",
    "        else:\n",
    "            print(f\"    !No checksum values returned from download request for {filename}.\")\n",
    "        \n",
    "        \n",
    "        sema.release()\n",
    "    except Exception as e:\n",
    "        print(f\"    !!Failed to download {filename} -- {url}. Will try to re-download.\")\n",
    "        sema.release()\n",
    "        runDownload(threads,download_rq_result, out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def runDownload(threads, download_rq_result, out_dir):\n",
    "    thread = threading.Thread(target=downloadFile, args=(download_rq_result,out_dir,))\n",
    "    threads.append(thread)\n",
    "    thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your output directory\n",
    "out_dir = (\"/Users/hstouter/Library/CloudStorage/Box-Box/LCLUC_hs/Landsat_USGS/2024\")\n",
    "os.chdir(out_dir)  # switch to that directory\n",
    "print(out_dir)\n",
    "\n",
    "\n",
    "data_dir = 'data'\n",
    "\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting mulithreading parameters\n",
    "\n",
    "maxthreads = 5 # Threads count for downloads\n",
    "sema = threading.Semaphore(value=maxthreads)\n",
    "label = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") # Customized label using date time\n",
    "threads = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the payload for the download options request\n",
    "download_opt_payload = {\n",
    "    \"listId\": listId,              \n",
    "    \"datasetName\": datasetName      \n",
    "}\n",
    "\n",
    "# Print the payload for debugging purposes\n",
    "print(f\"download_opt_payload: {download_opt_payload}\")\n",
    "\n",
    "# Send request to the download options endpoint and retrieve list of available products\n",
    "products = sendRequest(serviceUrl + \"download-options\", download_opt_payload, apiKey)\n",
    "pd.json_normalize(products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products[1]['secondaryDownloads'][0]['checksum'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloads = []\n",
    "for product in products:  \n",
    "    if product[\"secondaryDownloads\"] is not None and len(product[\"secondaryDownloads\"]) > 0:\n",
    "        for secondaryDownload in product[\"secondaryDownloads\"]:\n",
    "            for bandName in bandNames:\n",
    "                if secondaryDownload[\"bulkAvailable\"] and bandName in secondaryDownload['displayId']:\n",
    "                    downloads.append({\"entityId\":secondaryDownload[\"entityId\"], \"productId\":secondaryDownload[\"id\"]})\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_req_payload = {\n",
    "        \"downloads\": downloads,\n",
    "        \"label\": label\n",
    "    }\n",
    "\n",
    "download_req_payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send the download request using the provided payload and store the results\n",
    "download_request_results = sendRequest(serviceUrl + \"download-request\", download_req_payload, apiKey)\n",
    "\n",
    "# Check if any new records or duplicate products were returned\n",
    "if len(download_request_results['newRecords']) == 0 and len(download_request_results['duplicateProducts']) == 0:\n",
    "    print('No records returned, please update your scenes or scene-search filter')\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(download_request_results) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dl in download_request_results['availableDownloads']:\n",
    "    print(f\"{dl['entityId']}: \\n {dl['checksum_values']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start download\n",
    "\n",
    "def run_download_retrieve(download_request_results, out_dir):\n",
    "    \n",
    "    # Attempt to download URLs if available\n",
    "    if len(download_request_results['availableDownloads']) > 0:\n",
    "        print(f\"Downloading {len(download_request_results['availableDownloads'])} files... Please do not close the program\\n\")\n",
    "        for result in download_request_results['availableDownloads']:  \n",
    "            # print(f\"Get download url: {result['url']}\\n\" )\n",
    "            runDownload(threads, result, out_dir)\n",
    "    \n",
    "    # Get items labeled as being prepared for Download\n",
    "    elif len(download_request_results['preparingDownloads']) > 0:\n",
    "        print(f\"Preparing Downloads for {len(download_request_results['preparingDownloads'])} files... Please do not close the program\\n\")\n",
    "    \n",
    "        preparingDownloadIds = []\n",
    "    \n",
    "        for result in download_request_results['preparingDownloads']:  \n",
    "            preparingDownloadIds.append(result['downloadId'])\n",
    "    \n",
    "        download_ret_payload = {\"label\" : download_req_payload['label']}                \n",
    "        # Retrieve download URLs\n",
    "        print(\"Retrieving download urls...\\n\")\n",
    "        download_retrieve_results = sendRequest(serviceUrl + \"download-retrieve\", download_ret_payload, apiKey, False)\n",
    "        print(f\"download_retrieve_results: {download_retrieve_results}\")\n",
    "        if download_retrieve_results != False:\n",
    "            print(f\"    Download-retrieve complete: \\n\" )\n",
    "            for result in download_retrieve_results['available']:\n",
    "                if result['downloadId'] in preparingDownloadIds:\n",
    "                    preparingDownloadIds.remove(result['downloadId'])\n",
    "                    runDownload(threads, result, out_dir)\n",
    "                    print(f\"       {result['url']}\\n\" )\n",
    "    \n",
    "            for result in download_retrieve_results['requested']:   \n",
    "                if result['downloadId'] in preparingDownloadIds:\n",
    "                    preparingDownloadIds.remove(result['downloadId'])\n",
    "                    runDownload(threads, result, out_dir)\n",
    "                    print(f\"       {result['url']}\\n\" )\n",
    "    \n",
    "        # Didn't get all download URLs, retrieve again after 30 seconds\n",
    "        while len(preparingDownloadIds) > 0: \n",
    "            print(f\"{len(preparingDownloadIds)} downloads are not available yet. Waiting for 30s to retrieve again\\n\")\n",
    "            time.sleep(30)\n",
    "            download_retrieve_results = sendRequest(serviceUrl + \"download-retrieve\", download_ret_payload, apiKey, False)\n",
    "            if download_retrieve_results != False:\n",
    "                for result in download_retrieve_results['available']:                            \n",
    "                    if result['downloadId'] in preparingDownloadIds:\n",
    "                        preparingDownloadIds.remove(result['downloadId'])\n",
    "                        print(f\"    Get download url: {result['url']}\\n\" )\n",
    "                        runDownload(threads, result, out_dir)\n",
    "    \n",
    "    for thread in threads:\n",
    "        thread.join()        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_download_retrieve(download_request_results, data_dir) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "remote_sensing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
